{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_context_vector(context, word_to_ix):\n",
    "    idxs = [word_to_ix[w] for w in context]\n",
    "    tensor = torch.LongTensor(idxs)\n",
    "    return Variable(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CONTEXT_SIZE = 4  # 2 words to the left, 2 to the right\n",
    "EMBEDDING_DIM = 4500\n",
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_text = \"\"\"We are about to study the idea of a computational process.\n",
    "Computational processes are abstract beings that inhabit computers.\n",
    "As they evolve, processes manipulate other abstract things called data.\n",
    "The evolution of a process is directed by a pattern of rules\n",
    "called a program. People create programs to direct processes. In effect,\n",
    "we conjure the spirits of the computer with our spells.\"\"\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigrams = [([raw_text[i], raw_text[i + 1], raw_text[i + 2], raw_text[i + 3]], raw_text[i + 2])\n",
    "            for i in range(len(raw_text) - 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = set(raw_text)\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['We', 'are', 'to', 'study'], 'about'), (['are', 'about', 'study', 'the'], 'to'), (['about', 'to', 'the', 'idea'], 'study'), (['to', 'study', 'idea', 'of'], 'the'), (['study', 'the', 'of', 'a'], 'idea')]\n"
     ]
    }
   ],
   "source": [
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "data = []\n",
    "for i in range(2, len(raw_text) - 2):\n",
    "    context = [raw_text[i - 2], raw_text[i - 1],\n",
    "               raw_text[i + 1], raw_text[i + 2]]\n",
    "    target = raw_text[i]\n",
    "    data.append((context, target))\n",
    "print(data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CBOW(nn.Module):\n",
    "    global intermediaire\n",
    "    def __init__(self, vocab_size, embedding_dim, context_size):\n",
    "        super(CBOW, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.linear1 = nn.Linear(context_size * embedding_dim, 64)\n",
    "        self.linear2 = nn.Linear(64, vocab_size)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        embeds = self.embeddings(inputs).view((1, -1))\n",
    "        out = F.relu(self.linear1(embeds))\n",
    "        intermediaire = out\n",
    "        out = self.linear2(out)\n",
    "        log_probs = F.log_softmax(out)\n",
    "        return log_probs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss_function = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = CBOW(len(vocab), EMBEDDING_DIM, CONTEXT_SIZE)\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "courbe_apprentissage = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    total_loss = torch.Tensor([0])\n",
    "    for context, target in trigrams:\n",
    "\n",
    "        # Step 1. Prepare the inputs to be passed to the model (i.e, turn the words\n",
    "        # into integer indices and wrap them in variables)\n",
    "        context_idxs = [word_to_ix[w] for w in context]\n",
    "        context_var = Variable(torch.LongTensor(context_idxs))\n",
    "\n",
    "        # Step 2. Recall that torch *accumulates* gradients. Before passing in a\n",
    "        # new instance, you need to zero out the gradients from the old\n",
    "        # instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 3. Run the forward pass, getting log probabilities over next\n",
    "        # words\n",
    "        log_probs = model(context_var)\n",
    "\n",
    "        # Step 4. Compute your loss function. (Again, Torch wants the target\n",
    "        # word wrapped in a variable)\n",
    "        loss = loss_function(log_probs, Variable(\n",
    "            torch.LongTensor([word_to_ix[target]])))\n",
    "\n",
    "        # Step 5. Do the backward pass and update the gradient\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.data\n",
    "    courbe_apprentissage.append(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110863160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(courbe_apprentissage)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2401\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courbe_apprentissage[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 40\n",
       " 37\n",
       " 21\n",
       " 13\n",
       "[torch.LongTensor of size 4]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppx/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:14: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "lolo = model(Variable(torch.LongTensor([1,2,3,4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = loss_function(lolo, Variable(\n",
    "            torch.LongTensor([word_to_ix['data.']])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-6.1871 -4.5681 -4.7636 -1.9886 -4.8791 -6.8418 -6.4438 -5.1992 -7.3156 -4.9472\n",
       "\n",
       "Columns 10 to 19 \n",
       "-4.8338 -6.5393 -4.7779 -7.1557 -4.8266 -5.8855 -3.5777 -2.6375 -6.7238 -6.1792\n",
       "\n",
       "Columns 20 to 29 \n",
       "-4.1606 -5.4338 -4.6953 -7.0794 -7.3901 -5.9422 -6.1656 -6.1227 -5.0742 -5.4529\n",
       "\n",
       "Columns 30 to 39 \n",
       "-6.9456 -5.2449 -1.1402 -4.9332 -7.3816 -5.2458 -4.4749 -2.0492 -6.0436 -3.3535\n",
       "\n",
       "Columns 40 to 48 \n",
       "-6.7605 -5.6078 -5.1385 -5.3530 -3.8456 -5.1770 -5.1194 -4.1853 -2.8450\n",
       "[torch.FloatTensor of size 1x49]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lolo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'with'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
